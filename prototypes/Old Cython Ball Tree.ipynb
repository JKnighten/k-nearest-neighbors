{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change Working Directory To Allow knn Imports\n",
    "import os \n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# MNIST Data\n",
    "# Load Data\n",
    "mnist_data = np.load('./sample_data/mnist/mnist_data.npz')\n",
    "train_data = mnist_data['train_data']\n",
    "test_data = mnist_data['test_data']\n",
    "\n",
    "# Subset Data If Desired\n",
    "test_labels = test_data[:100, 0]\n",
    "test_data = test_data[:100, 1:4].astype(np.float)\n",
    "train_labels = train_data[100:1100, 0]\n",
    "train_data = train_data[100:1100, 1:4].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import heapq\n",
    "from knn.distance_metrics import euclidean_pairwise\n",
    "\n",
    "metric = euclidean_pairwise\n",
    "\n",
    "#Wrapper Over heapq\n",
    "class PriorityQueue:\n",
    "\n",
    "    def __init__(self, is_min_heap=True):\n",
    "        self.queue = []\n",
    "        self.cnt = Counter()\n",
    "        self.is_min_heap = is_min_heap\n",
    "\n",
    "    def heappush(self, priority, value):\n",
    "        self.cnt[priority] += 1\n",
    "        q_priority = priority if self.is_min_heap else -1*priority\n",
    "        heapq.heappush(self.queue, (q_priority, self.cnt[priority], value))\n",
    "\n",
    "    def heappushpop(self, priority, value):\n",
    "        self.cnt[priority] += 1\n",
    "        q_priority = priority if self.is_min_heap else -1*priority\n",
    "        heapq.heappushpop(self.queue, (q_priority, self.cnt[priority], value))\n",
    "\n",
    "    def heappop(self):\n",
    "        curr_top = heapq.heappop(self.queue)\n",
    "        q_priority = curr_top[0] if self.is_min_heap else -1*curr_top[0]\n",
    "        return q_priority, curr_top[2]\n",
    "\n",
    "    def peektop(self):\n",
    "        curr_top = self.queue[0]\n",
    "        q_priority = curr_top[0] if self.is_min_heap else -1*curr_top[0]\n",
    "        return q_priority, curr_top[2]\n",
    "    \n",
    "def create_ball_tree(data, leaf_size):\n",
    "\n",
    "    if data.shape[0] <= leaf_size:\n",
    "        leaf_node = {}\n",
    "        leaf_node[\"center\"] = np.mean(data, axis=0)[np.newaxis, :]\n",
    "        leaf_node[\"radius\"] = np.max(metric(data, leaf_node[\"center\"]))\n",
    "        leaf_node[\"data\"] = data\n",
    "        return leaf_node\n",
    "\n",
    "    # Random Point x0\n",
    "    rand_index = np.random.choice(data.shape[0], 1, replace=False)\n",
    "    rand_point = data[rand_index, :]\n",
    "\n",
    "    # Find Maximal Point x1\n",
    "    distances = metric(data, rand_point)\n",
    "    ind_of_max_dist = np.argmax(distances)\n",
    "    max_vector_1 = data[ind_of_max_dist, :]\n",
    "\n",
    "    # Find Maximal Point x2\n",
    "    distances = metric(data, max_vector_1[np.newaxis, :])\n",
    "    ind_of_max_dist = np.argmax(distances)\n",
    "    max_vector_2 = data[ind_of_max_dist, :]\n",
    "\n",
    "    # Project Data\n",
    "    proj_data = data.dot(max_vector_1-max_vector_2)\n",
    "\n",
    "    # Find Median And Split Data\n",
    "    median_ind = np.argpartition(proj_data, proj_data.size//2)\n",
    "    lower_than_med_inds = median_ind[:proj_data.size//2]\n",
    "    greater_than_med_inds = median_ind[proj_data.size//2:]\n",
    "\n",
    "    # Create Circle\n",
    "    center = np.mean(data, axis=0)\n",
    "    radius = np.max(metric(data, center[np.newaxis, :]))\n",
    "\n",
    "    internal_node = {}\n",
    "    internal_node[\"center\"] = center[np.newaxis, :]\n",
    "    internal_node[\"radius\"] = radius\n",
    "    internal_node[\"left_child\"] = create_ball_tree(data[lower_than_med_inds], leaf_size)\n",
    "    internal_node[\"right_child\"] = create_ball_tree(data[greater_than_med_inds], leaf_size)\n",
    "\n",
    "    return internal_node\n",
    "\n",
    "def query_ball_tree(target_vect, k, queue, curr_node):\n",
    "\n",
    "    # Prune This Ball\n",
    "    if metric(target_vect, curr_node[\"center\"]) - curr_node[\"radius\"] >= queue.peektop()[0]:\n",
    "        return queue\n",
    "\n",
    "    # Currently A Leaf Node\n",
    "    if \"data\" in curr_node:\n",
    "        for point in curr_node[\"data\"]:\n",
    "            dist = np.asscalar(metric(target_vect, point[np.newaxis, :]))\n",
    "            if dist < queue.peektop()[0]:\n",
    "                queue.heappushpop(dist, point)\n",
    "\n",
    "    # Not Leaf So Explore Children\n",
    "    else:\n",
    "        child1 = curr_node[\"left_child\"]\n",
    "        child2 = curr_node[\"right_child\"]\n",
    "\n",
    "        child1_dist = metric(child1[\"center\"], target_vect)\n",
    "        child2_dist = metric(child2[\"center\"], target_vect)\n",
    "\n",
    "        if child1_dist < child2_dist:\n",
    "            query_ball_tree(target_vect, k, queue, child1)\n",
    "            query_ball_tree(target_vect, k, queue, child2)\n",
    "        else:\n",
    "            query_ball_tree(target_vect, k, queue, child2)\n",
    "            query_ball_tree(target_vect, k, queue, child1)\n",
    "            \n",
    "            \n",
    "def classify_ball_tree(test_data, train_data,labels, k, tree):\n",
    "    output_labels = []\n",
    "    for test_vector in test_data:\n",
    "        queue = PriorityQueue(False)\n",
    "        # Fill queue With High Distance Points\n",
    "        list(map(lambda x: queue.heappush(9e10, np.array([9e10, 9e10])), range(k)))\n",
    "        query_ball_tree(test_vector[np.newaxis, :], k, queue, tree)\n",
    "        nn_points = np.array([x[2] for x in queue.queue])[:, np.newaxis]\n",
    "        predicted_labels = labels[np.where((train_data == nn_points).all(-1))[1]]\n",
    "        output_labels.append(np.bincount(predicted_labels).argmax())\n",
    "    return np.array(output_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.38 ms ± 343 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "524 ms ± 6.59 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "metric = euclidean_pairwise\n",
    "ball_tree = create_ball_tree(train_data, 25)\n",
    "%timeit ball_tree = create_ball_tree(train_data, 25)\n",
    "%timeit classify_ball_tree(train_data, train_data, train_labels, 3, ball_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython \n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from knn.distance_metrics import euclidean_pairwise\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def query_ball_tree_cyth(np.ndarray[double, ndim=2] target_vect, int k, queue, dict curr_node):\n",
    "\n",
    "    \n",
    "    cdef size_t i\n",
    "    cdef int numb_points\n",
    "    #cdef float dist\n",
    "    cdef np.ndarray[double, ndim=2] dists\n",
    "    \n",
    "    cdef dict child1\n",
    "    cdef dict child2\n",
    "    \n",
    "    cdef double child1_dist\n",
    "    cdef double child2_dist\n",
    "    \n",
    "    # Prune This Ball\n",
    "    if euclidean_pairwise(target_vect, curr_node[\"center\"]) - curr_node[\"radius\"] >= queue.peektop()[0]:\n",
    "        return queue\n",
    "    \n",
    "    if \"data\" in curr_node:\n",
    "        \n",
    "        numb_points = curr_node[\"data\"].shape[0]\n",
    "        dists = euclidean_pairwise(target_vect, curr_node[\"data\"])\n",
    "        \n",
    "        for i in range(numb_points):\n",
    "            if dists[i] < queue.peektop()[0]:\n",
    "                queue.heappushpop(np.asscalar(dists[i]), curr_node[\"data\"][i, :])\n",
    "    \n",
    "\n",
    "    # Not Leaf So Explore Children\n",
    "    else:\n",
    "       \n",
    "        child1_dist = euclidean_pairwise(curr_node[\"left_child\"][\"center\"], target_vect)\n",
    "        child2_dist = euclidean_pairwise(curr_node[\"right_child\"][\"center\"], target_vect)\n",
    "\n",
    "        if child1_dist < child2_dist:\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"left_child\"])\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"right_child\"])\n",
    "        else:\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"right_child\"])\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"left_child\"])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_ball_tree_cyth(test_data, train_data,labels, k, tree):\n",
    "    output_labels = []\n",
    "    for test_vector in test_data:\n",
    "        queue = PriorityQueue(False)\n",
    "        # Fill queue With High Distance Points\n",
    "        list(map(lambda x: queue.heappush(9e10, np.array([9e10, 9e10])), range(k)))\n",
    "        query_ball_tree_cyth(test_vector[np.newaxis, :], k, queue, tree)\n",
    "        nn_points = np.array([x[2] for x in queue.queue])[:, np.newaxis]\n",
    "        predicted_labels = labels[np.where((train_data == nn_points).all(-1))[1]]\n",
    "        output_labels.append(np.bincount(predicted_labels).argmax())\n",
    "    return np.array(output_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429 ms ± 17.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "ball_tree = create_ball_tree(train_data, 25)\n",
    "%timeit classify_ball_tree_cyth(train_data, train_data, train_labels, 3, ball_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precompute Distance Between Test Points And Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Leafs: 100\n",
      "Tree Height: 8\n",
      "Number Of Nodes: 255\n",
      "(255, 3)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "leaf_size = 10\n",
    "numb_of_leafs = math.ceil(train_data.shape[0] / leaf_size)\n",
    "print(\"Number of Leafs: \" + str(numb_of_leafs))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tree_height =  1 + math.ceil(np.log2(numb_of_leafs))\n",
    "print(\"Tree Height: \" +  str(tree_height))\n",
    "\n",
    "\n",
    "numb_of_nodes = int(2 ** tree_height) - 1 \n",
    "print(\"Number Of Nodes: \" +  str(numb_of_nodes))\n",
    "\n",
    "centroids_s = np.zeros((numb_of_nodes, test_data.shape[1]))\n",
    "\n",
    "print(centroids_s.shape)\n",
    "\n",
    "\n",
    "def create_ball_tree(data, leaf_size, centroids, index):\n",
    "    \n",
    "    \n",
    "    if data.shape[0] <= leaf_size:\n",
    "        leaf_node = {}\n",
    "        leaf_node[\"center\"] = np.mean(data, axis=0)[np.newaxis, :]\n",
    "        centroids[index, :] = leaf_node[\"center\"] # New\n",
    "        leaf_node[\"radius\"] = np.max(metric(data, leaf_node[\"center\"]))\n",
    "        leaf_node[\"data\"] = data\n",
    "        \n",
    "        \n",
    "        \n",
    "        return leaf_node\n",
    "\n",
    "    # Random Point x0\n",
    "    rand_index = np.random.choice(data.shape[0], 1, replace=False)\n",
    "    rand_point = data[rand_index, :]\n",
    "\n",
    "    # Find Maximal Point x1\n",
    "    distances = metric(data, rand_point)\n",
    "    ind_of_max_dist = np.argmax(distances)\n",
    "    max_vector_1 = data[ind_of_max_dist, :]\n",
    "\n",
    "    # Find Maximal Point x2\n",
    "    distances = metric(data, max_vector_1[np.newaxis, :])\n",
    "    ind_of_max_dist = np.argmax(distances)\n",
    "    max_vector_2 = data[ind_of_max_dist, :]\n",
    "\n",
    "    # Project Data\n",
    "    proj_data = data.dot(max_vector_1-max_vector_2)\n",
    "\n",
    "    # Find Median And Split Data\n",
    "    median_ind = np.argpartition(proj_data, proj_data.size//2)\n",
    "    lower_than_med_inds = median_ind[:proj_data.size//2]\n",
    "    greater_than_med_inds = median_ind[proj_data.size//2:]\n",
    "\n",
    "    # Create Circle\n",
    "    center = np.mean(data, axis=0)\n",
    "    radius = np.max(metric(data, center[np.newaxis, :]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    left_index = 2 * index + 1\n",
    "    right_index = left_index + 1\n",
    "\n",
    "    internal_node = {}\n",
    "    internal_node[\"center\"] = center[np.newaxis, :]\n",
    "    centroids[index, :] = internal_node[\"center\"] # New\n",
    "    internal_node[\"radius\"] = radius\n",
    "    internal_node[\"left_child\"] = create_ball_tree(data[lower_than_med_inds], leaf_size, centroids, left_index)\n",
    "    internal_node[\"right_child\"] = create_ball_tree(data[greater_than_med_inds], leaf_size, centroids, right_index)\n",
    "\n",
    "    return internal_node\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "leaf_size = 20\n",
    "numb_of_leafs = math.ceil(train_data.shape[0] / leaf_size)\n",
    "tree_height =  1 + math.ceil(np.log2(numb_of_leafs))\n",
    "numb_of_nodes = int(2 ** tree_height) - 1 \n",
    "centroids_s = np.zeros((numb_of_nodes, test_data.shape[1]))\n",
    "\n",
    "\n",
    "ball_tree = create_ball_tree(train_data, leaf_size, centroids_s, 0)\n",
    "\n",
    "centroid_dists = euclidean_pairwise(test_data, centroids_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from knn.distance_metrics import euclidean_pairwise\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def query_ball_tree_cyth(np.ndarray[double, ndim=2] target_vect, int k, queue, dict curr_node, np.ndarray[double, ndim=1] centroid_dists, int index):\n",
    "\n",
    "    cdef size_t i\n",
    "    cdef int numb_points\n",
    "    cdef np.ndarray[double, ndim=2] dists\n",
    "    cdef left_index, right_index\n",
    "    \n",
    "    # Prune This Ball\n",
    "    if centroid_dists[index] - curr_node[\"radius\"] >= queue.peektop()[0]:\n",
    "        return queue\n",
    "    \n",
    "    # Is Leaf\n",
    "    if \"data\" in curr_node:\n",
    "        \n",
    "        numb_points = curr_node[\"data\"].shape[0]\n",
    "        dists = euclidean_pairwise(target_vect, curr_node[\"data\"])\n",
    "        \n",
    "        for i in range(numb_points):\n",
    "            if dists[i] < queue.peektop()[0]:\n",
    "                queue.heappushpop(np.asscalar(dists[i]), curr_node[\"data\"][i, :])\n",
    "    \n",
    "\n",
    "    # Not Leaf So Explore Children\n",
    "    else:\n",
    "        \n",
    "        left_index = 2 * index + 1\n",
    "        right_index = left_index + 1\n",
    "       \n",
    "        if centroid_dists[left_index] < centroid_dists[right_index]:\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"left_child\"], centroid_dists,left_index)\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"right_child\"], centroid_dists,right_index)\n",
    "        else:\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"right_child\"], centroid_dists,right_index)\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"left_child\"], centroid_dists,left_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_ball_tree_cyth(test_data, train_data, labels, k, tree, centroids):\n",
    "    \n",
    "    centroid_dists = euclidean_pairwise(centroids, test_data)\n",
    "    \n",
    "    \n",
    "    output_labels = []\n",
    "    for i, test_vector in enumerate(test_data):\n",
    "        queue = PriorityQueue(False)\n",
    "        # Fill queue With High Distance Points\n",
    "        list(map(lambda x: queue.heappush(9e10, np.array([9e10, 9e10])), range(k)))\n",
    "        query_ball_tree_cyth(test_vector[np.newaxis, :], k, queue, tree, centroid_dists[i, :],0)\n",
    "        nn_points = np.array([x[2] for x in queue.queue])[:, np.newaxis]\n",
    "        predicted_labels = labels[np.where((train_data == nn_points).all(-1))[1]]\n",
    "        output_labels.append(np.bincount(predicted_labels).argmax())\n",
    "    return np.array(output_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "leaf_size = 10\n",
    "numb_of_leafs = math.ceil(train_data.shape[0] / leaf_size)\n",
    "tree_height =  1 + math.ceil(np.log2(numb_of_leafs))\n",
    "numb_of_nodes = int(2 ** tree_height) - 1 \n",
    "centroids_s = np.zeros((numb_of_nodes, test_data.shape[1]))\n",
    "\n",
    "ball_tree = create_ball_tree(train_data, leaf_size, centroids_s, 0)\n",
    "\n",
    "result = classify_ball_tree_cyth(train_data, train_data, train_labels, 3, ball_tree, centroids_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 ms ± 7.66 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit classify_ball_tree_cyth(train_data, train_data, train_labels, 3, ball_tree, centroids_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Cython To Exterior Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from knn.distance_metrics import euclidean_pairwise\n",
    "from collections import Counter\n",
    "import heapq\n",
    "\n",
    "#Wrapper Over heapq\n",
    "class PriorityQueue:\n",
    "\n",
    "    def __init__(self, is_min_heap=True):\n",
    "        self.queue = []\n",
    "        self.cnt = Counter()\n",
    "        self.is_min_heap = is_min_heap\n",
    "\n",
    "    def heappush(self, priority, value):\n",
    "        self.cnt[priority] += 1\n",
    "        q_priority = priority if self.is_min_heap else -1*priority\n",
    "        heapq.heappush(self.queue, (q_priority, self.cnt[priority], value))\n",
    "\n",
    "    def heappushpop(self, priority, value):\n",
    "        self.cnt[priority] += 1\n",
    "        q_priority = priority if self.is_min_heap else -1*priority\n",
    "        heapq.heappushpop(self.queue, (q_priority, self.cnt[priority], value))\n",
    "\n",
    "    def heappop(self):\n",
    "        curr_top = heapq.heappop(self.queue)\n",
    "        q_priority = curr_top[0] if self.is_min_heap else -1*curr_top[0]\n",
    "        return q_priority, curr_top[2]\n",
    "\n",
    "    def peektop(self):\n",
    "        curr_top = self.queue[0]\n",
    "        q_priority = curr_top[0] if self.is_min_heap else -1*curr_top[0]\n",
    "        return q_priority, curr_top[2]\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def query_ball_tree_cyth(np.ndarray[double, ndim=2] target_vect, int k, queue, dict curr_node, np.ndarray[double, ndim=1] centroid_dists, int index):\n",
    "\n",
    "    cdef size_t i\n",
    "    cdef int numb_points\n",
    "    cdef np.ndarray[double, ndim=2] dists\n",
    "    \n",
    "    # Prune This Ball\n",
    "    if centroid_dists[index] - curr_node[\"radius\"] >= queue.peektop()[0]:\n",
    "        return queue\n",
    "    \n",
    "    # Is Leaf\n",
    "    if \"data\" in curr_node:\n",
    "        \n",
    "        numb_points = curr_node[\"data\"].shape[0]\n",
    "        dists = euclidean_pairwise(target_vect, curr_node[\"data\"])\n",
    "        \n",
    "        for i in range(numb_points):\n",
    "            if dists[i] < queue.peektop()[0]:\n",
    "                queue.heappushpop(np.asscalar(dists[i]), curr_node[\"data\"][i, :])\n",
    "    \n",
    "    # Not Leaf So Explore Children\n",
    "    else:\n",
    "        \n",
    "        left_index = 2 * index + 1\n",
    "        right_index = left_index + 1\n",
    "       \n",
    "        if centroid_dists[left_index] < centroid_dists[right_index]:\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"left_child\"], centroid_dists, left_index)\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"right_child\"], centroid_dists, right_index)\n",
    "        else:\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"right_child\"], centroid_dists, right_index)\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"left_child\"], centroid_dists, left_index)\n",
    "            \n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)        \n",
    "def classify_ball_tree_cyth(np.ndarray[double, ndim=2] test_data, np.ndarray[double, ndim=2] train_data,\n",
    "                            np.ndarray[int, ndim=1]labels, int k, dict tree, np.ndarray[double, ndim=2]centroids):\n",
    "    \n",
    "    cdef size_t i, j, l, m\n",
    "    cdef int numb_test_points = test_data.shape[0]\n",
    "    cdef int numb_train_points = train_data.shape[0]\n",
    "    cdef int numb_features = test_data.shape[1]\n",
    "    \n",
    "    \n",
    "    cdef np.ndarray[double, ndim=2] centroid_dists = euclidean_pairwise(centroids, test_data)\n",
    "    \n",
    "    \n",
    "    cdef np.ndarray[int, ndim=1] output_labels = np.zeros(numb_test_points, dtype=np.int32)\n",
    "    \n",
    "    cdef np.ndarray[int, ndim=1] predicted_labels = np.zeros(k, dtype=np.int32)\n",
    "    \n",
    "    cdef np.ndarray[double, ndim=3] nn_points\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(queues.shape)\n",
    "    \n",
    "    for i in range(numb_test_points):\n",
    "        queue = PriorityQueue(False)\n",
    "        list(map(lambda x: queue.heappush(9e10, np.array([9e10, 9e10])), range(k)))\n",
    "        query_ball_tree_cyth(test_data[i, :][np.newaxis, :], k, queue, tree, centroid_dists[i, :], 0)\n",
    "        \n",
    "        \n",
    "        nn_points = np.array([x[2] for x in queue.queue])[:, np.newaxis]\n",
    "        predicted_labels = labels[np.where((train_data == nn_points).all(-1))[1]]\n",
    "        \n",
    "        \n",
    "        \n",
    "#         for j in range(k):\n",
    "#             for l in range(numb_train_points):\n",
    "#                 equal = True\n",
    "#                 for m in range(numb_features):\n",
    "#                     if queue.queue[j][2][m] != train_data[l, m]:\n",
    "#                         equal = False\n",
    "#                 if equal:\n",
    "#                     predicted_labels[j] = labels[l]\n",
    "                \n",
    "        output_labels[i] = np.bincount(predicted_labels).argmax()\n",
    "    \n",
    "\n",
    "    return output_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 ms ± 10.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from knn.distance_metrics import manhattan_pairwise\n",
    "\n",
    "metric = manhattan_pairwise\n",
    "\n",
    "ball_tree = create_ball_tree(train_data, leaf_size, centroids_s, 0)\n",
    "\n",
    "%timeit result = classify_ball_tree_cyth(train_data, train_data, train_labels, 3, ball_tree, centroids_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Store Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "(100,)\n",
      "(100, 4)\n",
      "[1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "print(np.arange(test_data.shape[0]).shape)\n",
    "\n",
    "test_data_with_inds = np.hstack((np.arange(test_data.shape[0])[:, np.newaxis], test_data))\n",
    "train_data_with_inds = np.hstack((np.arange(train_data.shape[0])[:, np.newaxis], train_data))\n",
    "\n",
    "print(test_data_with_inds.shape)\n",
    "print(test_data_with_inds[1:5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_ball_tree(data, leaf_size, centroids, index):\n",
    "    \n",
    "    \n",
    "    if data.shape[0] <= leaf_size:\n",
    "        leaf_node = {}\n",
    "        leaf_node[\"center\"] = np.mean(data[:, 1:], axis=0)[np.newaxis, :]\n",
    "        centroids[index, :] = leaf_node[\"center\"] # New\n",
    "        leaf_node[\"radius\"] = np.max(metric(data[:, 1:], leaf_node[\"center\"]))\n",
    "        leaf_node[\"data\"] = data\n",
    "        return leaf_node\n",
    "\n",
    "    # Random Point x0\n",
    "    rand_index = np.random.choice(data.shape[0], 1, replace=False)\n",
    "    rand_point = data[rand_index, 1:]\n",
    "    \n",
    "    \n",
    "\n",
    "    # Find Maximal Point x1\n",
    "    distances = metric(data[:, 1:], rand_point)\n",
    "    ind_of_max_dist = np.argmax(distances)\n",
    "    max_vector_1 = data[ind_of_max_dist, 1:]\n",
    "    \n",
    "    \n",
    "\n",
    "    # Find Maximal Point x2\n",
    "    distances = metric(data[:, 1:], max_vector_1[np.newaxis, :])\n",
    "    ind_of_max_dist = np.argmax(distances)\n",
    "    max_vector_2 = data[ind_of_max_dist, 1:]\n",
    "    \n",
    "    \n",
    "\n",
    "    # Project Data\n",
    "    proj_data = data[:, 1:].dot(max_vector_1-max_vector_2)\n",
    "\n",
    "    # Find Median And Split Data\n",
    "    median_ind = np.argpartition(proj_data, proj_data.size//2)\n",
    "    lower_than_med_inds = median_ind[:proj_data.size//2]\n",
    "    greater_than_med_inds = median_ind[proj_data.size//2:]\n",
    "\n",
    "    # Create Circle\n",
    "    center = np.mean(data[:, 1:], axis=0)\n",
    "    radius = np.max(metric(data[:, 1:], center[np.newaxis, :]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    left_index = 2 * index + 1\n",
    "    right_index = left_index + 1\n",
    "\n",
    "    internal_node = {}\n",
    "    internal_node[\"center\"] = center[np.newaxis, :]\n",
    "    centroids[index, :] = internal_node[\"center\"] # New\n",
    "    internal_node[\"radius\"] = radius\n",
    "    internal_node[\"left_child\"] = create_ball_tree(data[lower_than_med_inds], leaf_size, centroids, left_index)\n",
    "    internal_node[\"right_child\"] = create_ball_tree(data[greater_than_med_inds], leaf_size, centroids, right_index)\n",
    "\n",
    "    return internal_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ndarray is not C-contiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-61204160f473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcentroids_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumb_of_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mball_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ball_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_with_inds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-018a4823b883>\u001b[0m in \u001b[0;36mcreate_ball_tree\u001b[0;34m(data, leaf_size, centroids, index)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Find Maximal Point x1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mind_of_max_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmax_vector_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_of_max_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/k-nearest-neighbors/knn/distance_metrics.pyx\u001b[0m in \u001b[0;36mknn.distance_metrics.manhattan_pairwise\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Python Wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mmanhattan_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mvectors_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mvectors_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_manhattan_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectors_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/k-nearest-neighbors/knn/distance_metrics.cpython-35m-darwin.so\u001b[0m in \u001b[0;36mView.MemoryView.memoryview_cwrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Code/k-nearest-neighbors/knn/distance_metrics.cpython-35m-darwin.so\u001b[0m in \u001b[0;36mView.MemoryView.memoryview.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ndarray is not C-contiguous"
     ]
    }
   ],
   "source": [
    "leaf_size = 10\n",
    "numb_of_leafs = math.ceil(train_data.shape[0] / leaf_size)\n",
    "tree_height =  1 + math.ceil(np.log2(numb_of_leafs))\n",
    "numb_of_nodes = int(2 ** tree_height) - 1 \n",
    "centroids_s = np.zeros((numb_of_nodes, test_data.shape[1]))\n",
    "\n",
    "ball_tree = create_ball_tree(train_data_with_inds, leaf_size, centroids_s, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython \n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from knn.distance_metrics import euclidean\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def query_ball_tree_cyth(np.ndarray[double, ndim=2] target_vect, int k, queue, dict curr_node, np.ndarray[double, ndim=1] centroid_dists, int index):\n",
    "\n",
    "    cdef size_t i\n",
    "    cdef int numb_points\n",
    "    cdef np.ndarray[double, ndim=2] dists\n",
    "    cdef left_index, right_index\n",
    "    \n",
    "    # Prune This Ball\n",
    "    if centroid_dists[index] - curr_node[\"radius\"] >= queue.peektop()[0]:\n",
    "        return queue\n",
    "    \n",
    "    # Is Leaf\n",
    "    if \"data\" in curr_node:\n",
    "        \n",
    "        numb_points = curr_node[\"data\"].shape[0]\n",
    "        dists = euclidean(target_vect, curr_node[\"data\"][:, 1:])\n",
    "        \n",
    "        for i in range(numb_points):\n",
    "            if dists[i] < queue.peektop()[0]:\n",
    "                queue.heappushpop(np.asscalar(dists[i]), curr_node[\"data\"][i, :])\n",
    "    \n",
    "\n",
    "    # Not Leaf So Explore Children\n",
    "    else:\n",
    "        \n",
    "        left_index = 2 * index + 1\n",
    "        right_index = left_index + 1\n",
    "       \n",
    "        if centroid_dists[left_index] < centroid_dists[right_index]:\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"left_child\"], centroid_dists,left_index)\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"right_child\"], centroid_dists,right_index)\n",
    "        else:\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"right_child\"], centroid_dists,right_index)\n",
    "            query_ball_tree_cyth(target_vect, k, queue, curr_node[\"left_child\"], centroid_dists,left_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_ball_tree_cyth(test_data, train_data, labels, k, tree, centroids):\n",
    "    \n",
    "    centroid_dists = euclidean(centroids, test_data)\n",
    "    \n",
    "    \n",
    "    output_labels = []\n",
    "    for i, test_vector in enumerate(test_data):\n",
    "        queue = PriorityQueue(False)\n",
    "        # Fill queue With High Distance Points\n",
    "        list(map(lambda x: queue.heappush(9e10, np.array([9e10, 9e10])), range(k)))\n",
    "        query_ball_tree_cyth(test_vector[np.newaxis, :], k, queue, tree, centroid_dists[i, :], 0)\n",
    "        \n",
    "        nn_points = np.array([x[2][0] for x in queue.queue], dtype=np.int)\n",
    "        \n",
    "        \n",
    "        \n",
    "        predicted_labels = labels[nn_points]\n",
    "        \n",
    "        output_labels.append(np.bincount(predicted_labels).argmax())\n",
    "    return np.array(output_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "leaf_size = 1\n",
    "numb_of_leafs = math.ceil(train_data.shape[0] / leaf_size)\n",
    "tree_height =  1 + math.ceil(np.log2(numb_of_leafs))\n",
    "numb_of_nodes = int(2 ** tree_height) - 1 \n",
    "centroids_s = np.zeros((numb_of_nodes, test_data.shape[1]))\n",
    "\n",
    "ball_tree = create_ball_tree(train_data_with_inds, leaf_size, centroids_s, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%timeit result = classify_ball_tree_cyth(train_data, train_data, train_labels, 3, ball_tree, centroids_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removed peektop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from knn.distance_metrics import euclidean\n",
    "\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "cpdef void query_ball_tree_cyth(np.ndarray[double, ndim=2] target_vect, int k, queue, dict curr_node, np.ndarray[double, ndim=1] centroid_dists, int index):\n",
    "\n",
    "    cdef size_t i\n",
    "    cdef int numb_points\n",
    "    cdef np.ndarray[double, ndim=2] dists\n",
    "    cdef int left_index, right_index\n",
    "    \n",
    "    # Prune This Ball\n",
    "    if centroid_dists[index] - curr_node[\"radius\"] < -1*queue.queue[0][0]:\n",
    "        \n",
    "        # Is Leaf\n",
    "        if \"data\" in curr_node:\n",
    "\n",
    "            numb_points = curr_node[\"data\"].shape[0]\n",
    "            dists = euclidean(target_vect, curr_node[\"data\"][:, 1:])\n",
    "\n",
    "            for i in range(numb_points):\n",
    "                if dists[i] < -1*queue.queue[0][0]:\n",
    "                    queue.heappushpop(np.asscalar(dists[i]), curr_node[\"data\"][i, :])\n",
    "\n",
    "\n",
    "        # Not Leaf So Explore Children\n",
    "        else:\n",
    "\n",
    "            left_index = 2 * index + 1\n",
    "            right_index = left_index + 1\n",
    "\n",
    "            if centroid_dists[left_index] < centroid_dists[right_index]:\n",
    "                query_ball_tree_cyth(target_vect, k, queue, curr_node[\"left_child\"], centroid_dists,left_index)\n",
    "                query_ball_tree_cyth(target_vect, k, queue, curr_node[\"right_child\"], centroid_dists,right_index)\n",
    "            else:\n",
    "                query_ball_tree_cyth(target_vect, k, queue, curr_node[\"right_child\"], centroid_dists,right_index)\n",
    "                query_ball_tree_cyth(target_vect, k, queue, curr_node[\"left_child\"], centroid_dists,left_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "leaf_size = 10\n",
    "numb_of_leafs = math.ceil(train_data.shape[0] / leaf_size)\n",
    "tree_height =  1 + math.ceil(np.log2(numb_of_leafs))\n",
    "numb_of_nodes = int(2 ** tree_height) - 1 \n",
    "centroids_s = np.zeros((numb_of_nodes, test_data.shape[1]))\n",
    "\n",
    "ball_tree = create_ball_tree(train_data_with_inds, leaf_size, centroids_s, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%timeit result = classify_ball_tree_cyth(train_data, train_data, train_labels, 3, ball_tree, centroids_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "import cython\n",
    "from cpython cimport bool\n",
    "\n",
    "from collections import Counter\n",
    "import heapq\n",
    "\n",
    "#Wrapper Over heapq\n",
    "cdef class PriorityQueue:\n",
    "    \n",
    "    cdef public list queue\n",
    "    cdef public object cnt\n",
    "    cdef public bool is_min_heap\n",
    "\n",
    "    def __init__(self, is_min_heap=True):\n",
    "        self.queue = []\n",
    "        self.cnt = Counter()\n",
    "        self.is_min_heap = is_min_heap\n",
    "\n",
    "    cpdef heappush(self, priority, value):\n",
    "        self.cnt[priority] += 1\n",
    "        q_priority = priority if self.is_min_heap else -1*priority\n",
    "        heapq.heappush(self.queue, (q_priority, self.cnt[priority], value))\n",
    "\n",
    "    cpdef heappushpop(self, priority, value):\n",
    "        self.cnt[priority] += 1\n",
    "        q_priority = priority if self.is_min_heap else -1*priority\n",
    "        heapq.heappushpop(self.queue, (q_priority, self.cnt[priority], value))\n",
    "\n",
    "    cpdef heappop(self):\n",
    "        curr_top = heapq.heappop(self.queue)\n",
    "        q_priority = curr_top[0] if self.is_min_heap else -1*curr_top[0]\n",
    "        return q_priority, curr_top[2]\n",
    "\n",
    "    cpdef peektop(self):\n",
    "        curr_top = self.queue[0]\n",
    "        q_priority = curr_top[0] if self.is_min_heap else -1*curr_top[0]\n",
    "        return q_priority, curr_top[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test= PriorityQueue()\n",
    "test.heappush(1, 5)\n",
    "print(test.queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from knn.distance_metrics import euclidean\n",
    "\n",
    "from collections import Counter\n",
    "import heapq\n",
    "from cpython cimport bool\n",
    "\n",
    "#Wrapper Over heapq\n",
    "cdef class PriorityQueue:\n",
    "    \n",
    "    cdef public list queue\n",
    "    cdef public object cnt\n",
    "    cdef public bool is_min_heap\n",
    "\n",
    "    def __init__(self, is_min_heap=True):\n",
    "        self.queue = []\n",
    "        self.cnt = Counter()\n",
    "        self.is_min_heap = is_min_heap\n",
    "\n",
    "    cpdef heappush(self, priority, value):\n",
    "        self.cnt[priority] += 1\n",
    "        q_priority = priority if self.is_min_heap else -1*priority\n",
    "        heapq.heappush(self.queue, (q_priority, self.cnt[priority], value))\n",
    "\n",
    "    cpdef heappushpop(self, priority, value):\n",
    "        self.cnt[priority] += 1\n",
    "        q_priority = priority if self.is_min_heap else -1*priority\n",
    "        heapq.heappushpop(self.queue, (q_priority, self.cnt[priority], value))\n",
    "\n",
    "    cpdef heappop(self):\n",
    "        curr_top = heapq.heappop(self.queue)\n",
    "        q_priority = curr_top[0] if self.is_min_heap else -1*curr_top[0]\n",
    "        return q_priority, curr_top[2]\n",
    "\n",
    "    cpdef peektop(self):\n",
    "        curr_top = self.queue[0]\n",
    "        q_priority = curr_top[0] if self.is_min_heap else -1*curr_top[0]\n",
    "        return q_priority, curr_top[2]\n",
    "\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "cpdef void query_ball_tree_cyth(np.ndarray[double, ndim=2] target_vect, int k, PriorityQueue queue,\n",
    "                                dict curr_node, np.ndarray[double, ndim=1] centroid_dists, int index):\n",
    "\n",
    "    cdef size_t i\n",
    "    cdef int numb_points\n",
    "    cdef np.ndarray[double, ndim=2] dists\n",
    "    cdef int left_index, right_index\n",
    "    \n",
    "    # Prune This Ball\n",
    "    if centroid_dists[index] - curr_node[\"radius\"] < -1*queue.queue[0][0]:\n",
    "        \n",
    "        # Is Leaf\n",
    "        if \"data\" in curr_node:\n",
    "\n",
    "            numb_points = curr_node[\"data\"].shape[0]\n",
    "            dists = euclidean(target_vect, curr_node[\"data\"][:, 1:])\n",
    "\n",
    "            for i in range(numb_points):\n",
    "                if dists[i] < -1*queue.queue[0][0]:\n",
    "                    queue.heappushpop(np.asscalar(dists[i]), curr_node[\"data\"][i, :])\n",
    "\n",
    "\n",
    "        # Not Leaf So Explore Children\n",
    "        else:\n",
    "\n",
    "            left_index = 2 * index + 1\n",
    "            right_index = left_index + 1\n",
    "\n",
    "            if centroid_dists[left_index] < centroid_dists[right_index]:\n",
    "                query_ball_tree_cyth(target_vect, k, queue, curr_node[\"left_child\"], centroid_dists,left_index)\n",
    "                query_ball_tree_cyth(target_vect, k, queue, curr_node[\"right_child\"], centroid_dists,right_index)\n",
    "            else:\n",
    "                query_ball_tree_cyth(target_vect, k, queue, curr_node[\"right_child\"], centroid_dists,right_index)\n",
    "                query_ball_tree_cyth(target_vect, k, queue, curr_node[\"left_child\"], centroid_dists,left_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "leaf_size = 10\n",
    "numb_of_leafs = math.ceil(train_data.shape[0] / leaf_size)\n",
    "tree_height =  1 + math.ceil(np.log2(numb_of_leafs))\n",
    "numb_of_nodes = int(2 ** tree_height) - 1 \n",
    "centroids_s = np.zeros((numb_of_nodes, test_data.shape[1]))\n",
    "\n",
    "ball_tree = create_ball_tree(train_data_with_inds, leaf_size, centroids_s, 0)\n",
    "\n",
    "%timeit result = classify_ball_tree_cyth(train_data, train_data, train_labels, 3, ball_tree, centroids_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knn_env_Python_3",
   "language": "python",
   "name": "knn_env_python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
