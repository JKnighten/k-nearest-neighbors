{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorized Distance Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: \n",
      "[[ 1.  2.  3.]\n",
      " [ 5.  6.  7.]\n",
      " [ 8.  9. 10.]]\n",
      "Test Data: \n",
      "[[ 5. 10. 15.]\n",
      " [10. 20. 30.]]\n"
     ]
    }
   ],
   "source": [
    "# Create Some Basic Testing Data\n",
    "import numpy as np\n",
    "\n",
    "train_data = np.array([[1., 2., 3.], [5., 6., 7.], [8., 9., 10.]])\n",
    "test_data = np.array([[5., 10., 15.], [10., 20., 30.]])\n",
    "\n",
    "print(\"Train Data: \\n\" + str(train_data))\n",
    "print(\"Test Data: \\n\" + str(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference Of Vectors: \n",
      "[[[ -4  -8 -12]\n",
      "  [  0  -4  -8]\n",
      "  [  3  -1  -5]]\n",
      "\n",
      " [[ -9 -18 -27]\n",
      "  [ -5 -14 -23]\n",
      "  [ -2 -11 -20]]]\n"
     ]
    }
   ],
   "source": [
    "# Find Difference Between Train and Test Vectors\n",
    "diff = train_data-test_data[:, np.newaxis]\n",
    "print(\"Difference Of Vectors: \\n\" + str(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square Of Differences: \n",
      "[[[ 16  64 144]\n",
      "  [  0  16  64]\n",
      "  [  9   1  25]]\n",
      "\n",
      " [[ 81 324 729]\n",
      "  [ 25 196 529]\n",
      "  [  4 121 400]]]\n"
     ]
    }
   ],
   "source": [
    "squares = np.square(diff)\n",
    "print(\"Square Of Differences: \\n\" + str(squares))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum Of Squares: \n",
      "[[ 224   80   35]\n",
      " [1134  750  525]]\n"
     ]
    }
   ],
   "source": [
    "sum_of_squares = np.sum(np.square(test), axis=2)\n",
    "print(\"Sum Of Squares: \\n\" + str(sum_of_squares))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix:\n",
      "[[14.96662955  8.94427191  5.91607978]\n",
      " [33.67491648 27.38612788 22.91287847]]\n"
     ]
    }
   ],
   "source": [
    "distance_matrix = np.sqrt(np.sum(np.square(test), axis=2))\n",
    "print(\"Distance Matrix:\\n\" + str(distance_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized Result: \n",
      "[[14.96662955  8.94427191  5.91607978]\n",
      " [33.67491648 27.38612788 22.91287847]]\n",
      "Non-Vectorized Result: \n",
      "[[14.96662955  8.94427191  5.91607978]\n",
      " [33.67491648 27.38612788 22.91287847]]\n",
      "Vectorized Timing:\n",
      "CPU times: user 1.02 ms, sys: 353 µs, total: 1.38 ms\n",
      "Wall time: 904 µs\n",
      "Non-Vectorized Timing:\n",
      "CPU times: user 39.2 ms, sys: 1.63 ms, total: 40.8 ms\n",
      "Wall time: 40 ms\n"
     ]
    }
   ],
   "source": [
    "from knn.distance_metrics import euclidean\n",
    "\n",
    "rand_train = np.random.randn(100,10)\n",
    "rand_test = np.random.randn(100,10)\n",
    "\n",
    "def euclidean_vect(train_data, test_data):\n",
    "    return np.sqrt(np.sum(np.square(train_data-test_data[:, np.newaxis]), axis=2))\n",
    "\n",
    "def euclidean_no_vect(train_data, test_data):\n",
    "    distance_matrix = np.zeros((test_data.shape[0], train_data.shape[0]))\n",
    "    for col, train_vect in enumerate(train_data):\n",
    "        for row, test_vect in enumerate(test_data):\n",
    "            distance_matrix[row, col] = euclidean(train_vect, test_vect)\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "print(\"Vectorized Result: \\n\" + str(euclidean_vect(train_data, test_data)))\n",
    "print(\"Non-Vectorized Result: \\n\" + str(euclidean_no_vect(train_data, test_data)))\n",
    "\n",
    "print(\"Vectorized Timing:\")\n",
    "%time result = euclidean_vect(rand_train, rand_test)\n",
    "print(\"Non-Vectorized Timing:\")\n",
    "%time result = euclidean_no_vect(rand_train, rand_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1-Norm or Manhattan Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference Of Vectors: \n",
      "[[[ -4  -8 -12]\n",
      "  [  0  -4  -8]\n",
      "  [  3  -1  -5]]\n",
      "\n",
      " [[ -9 -18 -27]\n",
      "  [ -5 -14 -23]\n",
      "  [ -2 -11 -20]]]\n"
     ]
    }
   ],
   "source": [
    "# Find Difference Between Train and Test Vectors\n",
    "diff = train_data-test_data[:, np.newaxis]\n",
    "print(\"Difference Of Vectors: \\n\" + str(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Differences: \n",
      "[[[ 4  8 12]\n",
      "  [ 0  4  8]\n",
      "  [ 3  1  5]]\n",
      "\n",
      " [[ 9 18 27]\n",
      "  [ 5 14 23]\n",
      "  [ 2 11 20]]]\n"
     ]
    }
   ],
   "source": [
    "absolute_diff = np.abs(diff)\n",
    "print(\"Absolute Differences: \\n\" + str(absolute_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix:\n",
      "[[24 12  9]\n",
      " [54 42 33]]\n"
     ]
    }
   ],
   "source": [
    "distance_matrix = np.sum(absolute_diff, axis=2)\n",
    "print(\"Distance Matrix:\\n\" + str(distance_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized Result: \n",
      "[[24 12  9]\n",
      " [54 42 33]]\n",
      "Non-Vectorized Result: \n",
      "[[24. 12.  9.]\n",
      " [54. 42. 33.]]\n",
      "Vectorized Timing:\n",
      "CPU times: user 1.23 ms, sys: 294 µs, total: 1.52 ms\n",
      "Wall time: 866 µs\n",
      "Non-Vectorized Timing:\n",
      "CPU times: user 40.8 ms, sys: 1.12 ms, total: 41.9 ms\n",
      "Wall time: 41.2 ms\n"
     ]
    }
   ],
   "source": [
    "from knn.distance_metrics import manhattan\n",
    "\n",
    "rand_train = np.random.randn(100,10)\n",
    "rand_test = np.random.randn(100,10)\n",
    "\n",
    "def manhattan_vect(train_data, test_data):\n",
    "    return np.sum(np.abs(train_data-test_data[:, np.newaxis]), axis=2)\n",
    "\n",
    "def manhattan_no_vect(train_data, test_data):\n",
    "    distance_matrix = np.zeros((test_data.shape[0], train_data.shape[0]))\n",
    "    for col, train_vect in enumerate(train_data):\n",
    "        for row, test_vect in enumerate(test_data):\n",
    "            distance_matrix[row, col] = manhattan(train_vect, test_vect)\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "print(\"Vectorized Result: \\n\" + str(manhattan_vect(train_data, test_data)))\n",
    "print(\"Non-Vectorized Result: \\n\" + str(manhattan_no_vect(train_data, test_data)))\n",
    "\n",
    "print(\"Vectorized Timing:\")\n",
    "%time result = euclidean_vect(rand_train, rand_test)\n",
    "print(\"Non-Vectorized Timing:\")\n",
    "%time result = euclidean_no_vect(rand_train, rand_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamming Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ True  True  True]\n",
      "  [False  True  True]\n",
      "  [ True  True  True]]\n",
      "\n",
      " [[ True  True  True]\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]]]\n"
     ]
    }
   ],
   "source": [
    "differences = train_data != test_data[:, np.newaxis]\n",
    "print(\"Logical Differences: \\n\" + str(differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum Of Differences: \n",
      "[[3 2 3]\n",
      " [3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "sum_of_diffs = np.sum(np.abs(train_data != test_data[:, np.newaxis]), axis=2)\n",
    "print(\"Sum Of Differences: \\n\" + str(sum_of_diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized Result: \n",
      "[[3 2 3]\n",
      " [3 3 3]]\n",
      "Non-Vectorized Result: \n",
      "[[3. 2. 3.]\n",
      " [3. 3. 3.]]\n",
      "Vectorized Timing:\n",
      "CPU times: user 1.83 ms, sys: 1.1 ms, total: 2.93 ms\n",
      "Wall time: 1.51 ms\n",
      "Non-Vectorized Timing:\n",
      "CPU times: user 70.8 ms, sys: 745 µs, total: 71.5 ms\n",
      "Wall time: 72.7 ms\n"
     ]
    }
   ],
   "source": [
    "from knn.distance_metrics import hamming\n",
    "\n",
    "rand_train = np.random.randn(100,10)\n",
    "rand_test = np.random.randn(100,10)\n",
    "\n",
    "def hamming_vect(train_data, test_data):\n",
    "    return np.sum(np.abs(train_data != test_data[:, np.newaxis]), axis=2)\n",
    "\n",
    "def hamming_no_vect(train_data, test_data):\n",
    "    distance_matrix = np.zeros((test_data.shape[0], train_data.shape[0]))\n",
    "    for col, train_vect in enumerate(train_data):\n",
    "        for row, test_vect in enumerate(test_data):\n",
    "            distance_matrix[row, col] = hamming(train_vect, test_vect)\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "print(\"Vectorized Result: \\n\" + str(hamming_vect(train_data, test_data)))\n",
    "print(\"Non-Vectorized Result: \\n\" + str(hamming_no_vect(train_data, test_data)))\n",
    "\n",
    "print(\"Vectorized Timing:\")\n",
    "%time result = hamming_vect(rand_train, rand_test)\n",
    "print(\"Non-Vectorized Timing:\")\n",
    "%time result = hamming_no_vect(rand_train, rand_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Vector Norms:\n",
      "[ 14 110 245]\n",
      "Test Vector Norms:\n",
      "[ 350 1400]\n"
     ]
    }
   ],
   "source": [
    "train_norms = np.sum(np.square(train_data), axis=1)\n",
    "test_norms = np.sum(np.square(test_data), axis=1)\n",
    "print(\"Train Vector Norms:\\n\" + str(train_norms))\n",
    "print(\"Test Vector Norms:\\n\" + str(test_norms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Of Norms:\n",
      "[[  4900  19600]\n",
      " [ 38500 154000]\n",
      " [ 85750 343000]]\n"
     ]
    }
   ],
   "source": [
    "prod_of_norms = np.outer(train_norms, test_norms)\n",
    "print(\"Product Of Norms:\\n\" + str(prod_of_norms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot Products:\n",
      "[[ 70 140]\n",
      " [190 380]\n",
      " [280 560]]\n"
     ]
    }
   ],
   "source": [
    "dots = np.dot(train_data, test_data.T)\n",
    "print(\"Dot Products:\\n\" + str(dots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix:\n",
      "[[0.01428571 0.00714286]\n",
      " [0.00493506 0.00246753]\n",
      " [0.00326531 0.00163265]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = dots/norm_prods\n",
    "print(\"Similarity Matrix:\\n\" + str(similarity_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized Result: \n",
      "[[0.         0.03167034 0.04381711]\n",
      " [0.         0.03167034 0.04381711]]\n",
      "Non-Vectorized Result: \n",
      "[[0.         0.03167034 0.04381711]\n",
      " [0.         0.03167034 0.04381711]]\n",
      "Vectorized Timing:\n",
      "CPU times: user 713 µs, sys: 323 µs, total: 1.04 ms\n",
      "Wall time: 727 µs\n",
      "Non-Vectorized Timing:\n",
      "CPU times: user 81 ms, sys: 1.31 ms, total: 82.3 ms\n",
      "Wall time: 82.6 ms\n"
     ]
    }
   ],
   "source": [
    "from knn.distance_metrics import cosine\n",
    "\n",
    "def cosine_vect(train_data, test_data):\n",
    "    train_norms = np.sqrt(np.sum(np.square(train_data), axis=1))\n",
    "    test_norms = np.sqrt(np.sum(np.square(test_data), axis=1))\n",
    "    return 1-(np.dot(train_data, test_data.T)/np.outer(train_norms, test_norms)).T\n",
    "\n",
    "def cosine_no_vect(train_data, test_data):\n",
    "    distance_matrix = np.zeros((test_data.shape[0], train_data.shape[0]))\n",
    "    for col, train_vect in enumerate(train_data):\n",
    "        for row, test_vect in enumerate(test_data):\n",
    "            distance_matrix[row, col] = cosine(train_vect, test_vect)\n",
    "    return distance_matrix\n",
    "            \n",
    "            \n",
    "print(\"Vectorized Result: \\n\" + str(cosine_vect(train_data, test_data)))\n",
    "print(\"Non-Vectorized Result: \\n\" + str(cosine_no_vect(train_data, test_data)))\n",
    "\n",
    "print(\"Vectorized Timing:\")\n",
    "%time result = cosine_vect(rand_train, rand_test)\n",
    "print(\"Non-Vectorized Timing:\")\n",
    "%time result = cosine_no_vect(rand_train, rand_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Removed Train:\n",
      "[[-1.  0.  1.]\n",
      " [-1.  0.  1.]\n",
      " [-1.  0.  1.]]\n",
      "Mean Removed Test:\n",
      "[[ -5.   0.   5.]\n",
      " [-10.   0.  10.]]\n"
     ]
    }
   ],
   "source": [
    "mean_removed_train = train_data-np.mean(train_data, axis=1)[:, np.newaxis]\n",
    "mean_removed_test = test_data-np.mean(test_data, axis=1)[:, np.newaxis,]\n",
    "\n",
    "print(\"Mean Removed Train:\\n\" + str(mean_removed_train))\n",
    "print(\"Mean Removed Test:\\n\" + str(mean_removed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std Dev Train:\n",
      "[1.41421356 1.41421356 1.41421356]\n",
      "Std Dev Train:\n",
      "[ 7.07106781 14.14213562]\n"
     ]
    }
   ],
   "source": [
    "std_dev_train = np.sqrt(np.sum(np.square(mean_removed_train), axis=1))\n",
    "print(\"Std Dev Train:\\n\" + str(std_dev_a))\n",
    "\n",
    "std_dev_test = np.sqrt(np.sum(np.square(mean_removed_test), axis=1))\n",
    "print(\"Std Dev Train:\\n\" + str(std_dev_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix:\n",
      "[[10. 20.]\n",
      " [10. 20.]\n",
      " [10. 20.]]\n"
     ]
    }
   ],
   "source": [
    "cov = np.dot(mean_removed_train, mean_removed_test.T)\n",
    "print(\"Covariance Matrix:\\n\" + str(cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std Dev Dots:\n",
      "[[10. 20.]\n",
      " [10. 20.]\n",
      " [10. 20.]]\n"
     ]
    }
   ],
   "source": [
    "std_dev_dot = np.outer(std_dev_train, std_dev_test)\n",
    "print(\"Std Dev Dots:\\n\" + str(std_dev_dot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlations:\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "correlations = cov/std_dev_dot\n",
    "print(\"Correlations:\\n\" + str(correlations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized Result: \n",
      "[[2.22044605e-16 2.22044605e-16]\n",
      " [2.22044605e-16 2.22044605e-16]\n",
      " [2.22044605e-16 2.22044605e-16]]\n",
      "Non-Vectorized Result: \n",
      "[[2.22044605e-16 2.22044605e-16 2.22044605e-16]\n",
      " [2.22044605e-16 2.22044605e-16 2.22044605e-16]]\n",
      "Vectorized Timing:\n",
      "CPU times: user 396 µs, sys: 222 µs, total: 618 µs\n",
      "Wall time: 405 µs\n",
      "Non-Vectorized Timing:\n",
      "CPU times: user 322 ms, sys: 10.5 ms, total: 332 ms\n",
      "Wall time: 328 ms\n"
     ]
    }
   ],
   "source": [
    "from knn.distance_metrics import pearson\n",
    "\n",
    "def pearson_vect(train_data, test_data):\n",
    "    mean_removed_train = (train_data-np.mean(train_data, axis=1)[:, np.newaxis])\n",
    "    mean_removed_test = (test_data-np.mean(test_data, axis=1)[:, np.newaxis])\n",
    "    std_dev_train = np.sqrt(np.sum(np.square(mean_removed_train), axis=1))\n",
    "    std_dev_test = np.sqrt(np.sum(np.square(mean_removed_test), axis=1))\n",
    "    return 1-np.dot(mean_removed_train, mean_removed_test.T)/np.outer(std_dev_train, std_dev_test)\n",
    "\n",
    "def pearson_no_vect(train_data, test_data):\n",
    "    distance_matrix = np.zeros((test_data.shape[0], train_data.shape[0]))\n",
    "    for col, train_vect in enumerate(train_data):\n",
    "        for row, test_vect in enumerate(test_data):\n",
    "            distance_matrix[row, col] = pearson(train_vect, test_vect)\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "\n",
    "print(\"Vectorized Result: \\n\" + str(pearson_vect(train_data, test_data)))\n",
    "print(\"Non-Vectorized Result: \\n\" + str(pearson_no_vect(train_data, test_data)))\n",
    "\n",
    "print(\"Vectorized Timing:\")\n",
    "%time result = pearson_vect(rand_train, rand_test)\n",
    "print(\"Non-Vectorized Timing:\")\n",
    "%time result = pearson_no_vect(rand_train, rand_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [ 5.  6.  7.]\n",
      " [ 8.  9. 10.]]\n",
      "[[ 5. 10. 15.]\n",
      " [10. 20. 30.]]\n",
      "All Column Sums:\n",
      "[[[ 6. 12. 18.]\n",
      "  [10. 16. 22.]\n",
      "  [13. 19. 25.]]\n",
      "\n",
      " [[11. 22. 33.]\n",
      "  [15. 26. 37.]\n",
      "  [18. 29. 40.]]]\n"
     ]
    }
   ],
   "source": [
    "all_col_sum = train_data + test_data[:, np.newaxis]\n",
    "print(\"All Column Sums:\\n\" + str(all_col_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Column Sums Reciprocal:\n",
      "[[[0.16666667 0.08333333 0.05555556]\n",
      "  [0.1        0.0625     0.04545455]\n",
      "  [0.07692308 0.05263158 0.04      ]]\n",
      "\n",
      " [[0.09090909 0.04545455 0.03030303]\n",
      "  [0.06666667 0.03846154 0.02702703]\n",
      "  [0.05555556 0.03448276 0.025     ]]]\n"
     ]
    }
   ],
   "source": [
    "all_col_sum_recip = np.reciprocal(all_col_sum, where=(all_col_sum != 0.0))\n",
    "print(\"All Column Sums Reciprocal:\\n\" + str(all_col_sum_recip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum Of Train Vectors:\n",
      "[ 6. 18. 27.]\n",
      "Sum Of Test Vectors:\n",
      "[30. 60.]\n"
     ]
    }
   ],
   "source": [
    "vector_train_sum = np.sum(train_data, axis=1)\n",
    "print(\"Sum Of Train Vectors:\\n\" + str(vector_train_sum))\n",
    "vector_test_sum = np.sum(test_data, axis=1)\n",
    "print(\"Sum Of Test Vectors:\\n\" + str(vector_test_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Freq Train Vectors:\n",
      "[[0.16666667 0.33333333 0.5       ]\n",
      " [0.27777778 0.33333333 0.38888889]\n",
      " [0.2962963  0.33333333 0.37037037]]\n",
      "Relative Freq Test Vectors:\n",
      "[[0.16666667 0.33333333 0.5       ]\n",
      " [0.16666667 0.33333333 0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "rel_freq_train = train_data/vector_train_sum[:, np.newaxis]\n",
    "print(\"Relative Freq Train Vectors:\\n\" + str(rel_freq_train))\n",
    "\n",
    "rel_freq_test = test_data/vector_test_sum[:, np.newaxis]\n",
    "print(\"Relative Freq Test Vectors:\\n\" + str(rel_freq_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference Between Relative Freq of Vectors:\n",
      "[[[ 0.          0.          0.        ]\n",
      "  [ 0.11111111  0.         -0.11111111]\n",
      "  [ 0.12962963  0.         -0.12962963]]\n",
      "\n",
      " [[ 0.          0.          0.        ]\n",
      "  [ 0.11111111  0.         -0.11111111]\n",
      "  [ 0.12962963  0.         -0.12962963]]]\n",
      "Difference Between Relative Freq of Vectors Squared:\n",
      "[[[0.         0.         0.        ]\n",
      "  [0.01234568 0.         0.01234568]\n",
      "  [0.01680384 0.         0.01680384]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.01234568 0.         0.01234568]\n",
      "  [0.01680384 0.         0.01680384]]]\n"
     ]
    }
   ],
   "source": [
    "diff_rel_freq = rel_freq_train-rel_freq_test[:, np.newaxis]\n",
    "print(\"Difference Between Relative Freq of Vectors:\\n\" + str(diff_rel_freq))\n",
    "\n",
    "diff_rel_freq_square = np.square(diff_rel_freq)\n",
    "print(\"Difference Between Relative Freq of Vectors Squared:\\n\" + str(diff_rel_freq_square))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product of Col Sums Recips and Diffs Of Rel Freq Squared:\n",
      "[[[0.         0.         0.        ]\n",
      "  [0.00123457 0.         0.00056117]\n",
      "  [0.0012926  0.         0.00067215]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.00082305 0.         0.00033367]\n",
      "  [0.00093355 0.         0.0004201 ]]]\n",
      "Sums of Products of Col Sums Recips and Diffs Of Rel Freq Squared:\n",
      "[[0.         0.00179574 0.00196476]\n",
      " [0.         0.00115671 0.00135364]]\n",
      "Chi Squared Stats: \n",
      "[[0.         0.04237612 0.04432558]\n",
      " [0.         0.03401047 0.03679188]]\n"
     ]
    }
   ],
   "source": [
    "recips_prod_with_diffs_rel_freq = all_col_sum_recip * diff_rel_freq_square\n",
    "print(\"Product of Col Sums Recips and Diffs Of Rel Freq Squared:\\n\" + str(recips_prod_with_diffs_rel_freq))\n",
    "\n",
    "sums_of_recips_prod_diffs_rel_freq = np.sum(all_col_sum_recip * diff_rel_freq_square, axis=2)\n",
    "print(\"Sums of Products of Col Sums Recips and Diffs Of Rel Freq Squared:\\n\" + str(sums_of_recips_prod_diffs_rel_freq))\n",
    "\n",
    "chisqr = np.sqrt(np.sum(all_col_sum_recip * diff_rel_freq_square, axis=2))\n",
    "print(\"Chi Squared Stats: \\n\" + str(chisqr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized Result: \n",
      "[[0.         0.04237612 0.04432558]\n",
      " [0.         0.03401047 0.03679188]]\n",
      "Non-Vectorized Result: \n",
      "[[0.         0.04237612 0.04432558]\n",
      " [0.         0.03401047 0.03679188]]\n",
      "Vectorized Timing:\n",
      "CPU times: user 2.15 ms, sys: 559 µs, total: 2.71 ms\n",
      "Wall time: 1.99 ms\n",
      "Non-Vectorized Timing:\n",
      "CPU times: user 306 ms, sys: 10.7 ms, total: 317 ms\n",
      "Wall time: 310 ms\n"
     ]
    }
   ],
   "source": [
    "from knn.distance_metrics import chisqr\n",
    "\n",
    "rand_train = np.random.randint(11, size=(100, 10))\n",
    "rand_test = np.random.randint(11, size=(100, 10))\n",
    "\n",
    "\n",
    "def chisqr_vect(train_data, test_data):\n",
    "    all_col_sum = train_data + test_data[:, np.newaxis]\n",
    "    all_col_sum_recip = np.reciprocal(all_col_sum, where=(all_col_sum != 0.0))\n",
    "    vector_train_sum = np.sum(train_data, axis=1)\n",
    "    vector_test_sum = np.sum(test_data, axis=1)\n",
    "    \n",
    "    rel_freq_train = np.divide(train_data, vector_train_sum[:, np.newaxis], \n",
    "                               out=np.full([train_data.shape[0], train_data.shape[1]], np.nan),\n",
    "                               where=(vector_train_sum[:, np.newaxis] != 0))\n",
    "    \n",
    "    rel_freq_test = np.divide(test_data, vector_test_sum[:, np.newaxis], \n",
    "                               out=np.full([test_data.shape[0], test_data.shape[1]], np.nan),\n",
    "                               where=(vector_test_sum[:, np.newaxis] != 0))\n",
    "    \n",
    "    diff_rel_freq_squared = np.square(rel_freq_train-rel_freq_test[:, np.newaxis])\n",
    "    chisqr = np.sqrt(np.sum(all_col_sum_recip * diff_rel_freq_squared, axis=2))\n",
    "    return chisqr\n",
    "\n",
    "def chisqr_no_vect(train_data, test_data):\n",
    "    distance_matrix = np.zeros((test_data.shape[0], train_data.shape[0]))\n",
    "    for col, train_vect in enumerate(train_data):\n",
    "        for row, test_vect in enumerate(test_data):\n",
    "            distance_matrix[row, col] = chisqr(train_vect, test_vect)\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "\n",
    "print(\"Vectorized Result: \\n\" + str(chisqr_vect(train_data, test_data)))\n",
    "print(\"Non-Vectorized Result: \\n\" + str(chisqr_no_vect(train_data, test_data)))\n",
    "\n",
    "print(\"Vectorized Timing:\")\n",
    "%time result = chisqr_vect(rand_train, rand_test)\n",
    "print(\"Non-Vectorized Timing:\")\n",
    "%time result = chisqr_no_vect(rand_train, rand_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking With KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_train = np.random.randn(1000,10)\n",
    "rand_test = np.random.randn(1000,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Introselect k=1: \n",
      "[[(2,  5.91607978) (1,  8.94427191)]\n",
      " [(2, 22.91287847) (1, 27.38612788)]]\n",
      "16.6 ms ± 1.16 ms per loop (mean ± std. dev. of 15 runs, 100 loops each)\n",
      "20.1 ms ± 348 µs per loop (mean ± std. dev. of 15 runs, 10 loops each)\n",
      "30.2 ms ± 134 µs per loop (mean ± std. dev. of 15 runs, 10 loops each)\n",
      "31.3 ms ± 230 µs per loop (mean ± std. dev. of 15 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "def knn_bf_introselect(train, test , distance, k=1):\n",
    "    distance_matrix = distance(train, test)\n",
    "    k_smallest_ind = np.argpartition(distance_matrix, k-1)[:,:k]\n",
    "    \n",
    "    smallest_k_matrix = np.zeros((test.shape[0], k), dtype=[(\"index\",int), (\"dist\",float)])\n",
    "    for i, ind_set in enumerate(k_smallest_ind):\n",
    "        for j, element in enumerate(ind_set):\n",
    "            smallest_k_matrix[i, j] = (element, distance_matrix[i, element])\n",
    "    \n",
    "    return smallest_k_matrix\n",
    "    \n",
    "\n",
    "print(\"KNN - Introselect k=1: \\n\" + str(knn_bf_introselect(train_data, test_data, euclidean_vect , 2)))\n",
    "\n",
    "%timeit -r 15 result_1 = knn_bf_introselect(rand_train, rand_test, cosine_vect, 1);\n",
    "%timeit -r 15 result_2 = knn_bf_introselect(rand_train, rand_test, cosine_vect, 3);\n",
    "%timeit -r 15 result_3 = knn_bf_introselect(rand_train, rand_test, cosine_vect, 5);\n",
    "%timeit -r 15 result_4 = knn_bf_introselect(rand_train, rand_test, cosine_vect, 7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Introselect k=1: \n",
      "[[(2,  5.91607978) (1,  8.94427191)]\n",
      " [(2, 22.91287847) (1, 27.38612788)]]\n",
      "16.6 ms ± 1.39 ms per loop (mean ± std. dev. of 15 runs, 100 loops each)\n",
      "20.7 ms ± 790 µs per loop (mean ± std. dev. of 15 runs, 10 loops each)\n",
      "31.5 ms ± 2.6 ms per loop (mean ± std. dev. of 15 runs, 10 loops each)\n",
      "32.2 ms ± 771 µs per loop (mean ± std. dev. of 15 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "def knn_bf_max_heap(train, test, distance, k=1):\n",
    "    distance_matrix = distance(train, test)\n",
    "    \n",
    "    smallest_k_matrix = np.zeros((test.shape[0], k), dtype=[(\"index\",int), (\"dist\",float)])\n",
    "    for index, row in enumerate(distance_matrix):\n",
    "        heapq.heapify(row.tolist())\n",
    "        smallest_k_matrix[index,:] = heapq.nsmallest(k, enumerate(row), key=lambda x: x[1])\n",
    "        \n",
    "    return smallest_k_matrix\n",
    "    \n",
    "    \n",
    "print(\"KNN - Introselect k=1: \\n\" + str(knn_bf_max_heap(train_data, test_data, euclidean_vect , 2)))\n",
    "%timeit -r 15 result_1 = knn_bf_introselect(rand_train, rand_test, cosine_vect, 1);\n",
    "%timeit -r 15 result_2 = knn_bf_introselect(rand_train, rand_test, cosine_vect, 3);\n",
    "%timeit -r 15 result_3 = knn_bf_introselect(rand_train, rand_test, cosine_vect, 5);\n",
    "%timeit -r 15 result_4 = knn_bf_introselect(rand_train, rand_test, cosine_vect, 7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knn_env_Python_3",
   "language": "python",
   "name": "knn_env_python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
