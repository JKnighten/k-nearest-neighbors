{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Brute Force Approach\n",
    "We first will explore KNN by looking at the brute force approach. In the brute force approach we do not use a special data structures to search through the data. We will simply calaculate the distance between every training vector and testing vector. As part of this exploration we will also look at algorithms for finding the K smallest numbers in an unordered collection of data.\n",
    "\n",
    "To begin will use the distance metrics created in the Distance Metrics notebook and explain why they cause a bottle neck. Later we will create updated distance metrics in the Vectorized Distance Metrics notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: \n",
      "[[ 1  2  3]\n",
      " [ 5  6  7]\n",
      " [ 8  9 10]]\n",
      "Test Data: \n",
      "[[ 5 10 15]\n",
      " [10 20 30]]\n"
     ]
    }
   ],
   "source": [
    "# Setup Some Test Data\n",
    "import numpy as np\n",
    "from knn.distance_metrics import euclidean\n",
    "\n",
    "train_data = np.array([[1, 2, 3], [5, 6, 7], [8, 9, 10]])\n",
    "test_data = np.array([[5, 10, 15], [10, 20, 30]])\n",
    "\n",
    "print(\"Train Data: \\n\" + str(train_data))\n",
    "print(\"Test Data: \\n\" + str(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Brute Force - Full Sort To Get Smallest K\n",
    "Here we use brute force KNN to find find all distances, then we fully sort the data to find the K smallest distances.\n",
    "Sorting the data to find the k smallest items will result in a time complexity of O(nlog)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 14.96662955) (1,  8.94427191) (2,  5.91607978)]\n",
      " [(0, 33.67491648) (1, 27.38612788) (2, 22.91287847)]]\n"
     ]
    }
   ],
   "source": [
    "# Quick Prototype #\n",
    "\n",
    "# Create A Distance Matrix. Each Row Represents A Test Vector And Each Column Is A Training Vector\n",
    "# Note: We Will Store The Index of The Training Vector and Its Distance. This Makes Classification and Regression\n",
    "#       Slightly Easier.\n",
    "distance_matrix = np.zeros((test_data.shape[0], train_data.shape[0]), dtype=[(\"index\",int), (\"dist\",float)])\n",
    "\n",
    "for row, test_vector in enumerate(test_data):\n",
    "    for col, train_vector in enumerate(train_data):\n",
    "        distance_matrix[row, col] = (col, euclidean(test_vector, train_vector))\n",
    "        \n",
    "print(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(2,  5.91607978) (1,  8.94427191)]\n",
      " [(2, 22.91287847) (1, 27.38612788)]]\n"
     ]
    }
   ],
   "source": [
    "# Sort To Find Smallest K\n",
    "k = 2\n",
    "sorted_distance_metric = np.sort(distance_matrix, order=\"dist\")\n",
    "smallest_k = sorted_distance_metric[:,:k]\n",
    "print(smallest_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Full Sort k=1: \n",
      "[[(2,  5.91607978)]\n",
      " [(2, 22.91287847)]]\n",
      "KNN - Full Sort k=2: \n",
      "[[(2,  5.91607978) (1,  8.94427191)]\n",
      " [(2, 22.91287847) (1, 27.38612788)]]\n",
      "KNN - Full Sort k=3: \n",
      "[[(2,  5.91607978) (1,  8.94427191) (0, 14.96662955)]\n",
      " [(2, 22.91287847) (1, 27.38612788) (0, 33.67491648)]]\n"
     ]
    }
   ],
   "source": [
    "# Make It All Into A Function\n",
    "def knn_bf_full_sort(train_data, test_data , k=1):\n",
    "    distance_matrix = np.zeros((test_data.shape[0], train_data.shape[0]), dtype=[(\"index\",int), (\"dist\",float)])\n",
    "\n",
    "    for row, test_vector in enumerate(test_data):\n",
    "        for col, train_vector in enumerate(train_data):\n",
    "            distance_matrix[row, col] = (col, euclidean(test_vector, train_vector))\n",
    "            \n",
    "    sorted_distance_metric = np.sort(distance_matrix, order=\"dist\")\n",
    "    smallest_k = sorted_distance_metric[:,:k]\n",
    "    return smallest_k\n",
    "    \n",
    "print(\"KNN - Full Sort k=1: \\n\" + str(knn_bf_full_sort(train_data, test_data, 1)))\n",
    "print(\"KNN - Full Sort k=2: \\n\" + str(knn_bf_full_sort(train_data, test_data, 2)))\n",
    "print(\"KNN - Full Sort k=3: \\n\" + str(knn_bf_full_sort(train_data, test_data, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Brute Force - Partial Sort To Get Smallest K\n",
    "Here we use brute force KNN to find find all distances, then we partial sort the data to get the smallest K. With partial sort we run K iterations of bubble sort to find top K, this results in a time complexity of O(kn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 1.) (6, 2.) (5, 3.)]\n"
     ]
    }
   ],
   "source": [
    "# Quick Prototype #\n",
    "\n",
    "# Create Some Data That Is The Same That WIll Be Encountered In Brute Force KNN\n",
    "sample_sort_data = np.array([(0, 8), (1, 7), (2, 6), (3, 5), (4, 4), (5, 3), (6, 2), (7, 1)],\n",
    "                            dtype=[(\"index\",int), (\"dist\",float)])\n",
    "\n",
    "k = 3\n",
    "# Bubble Sort Is Ran Backwards To Push The Smallest Values To The Front\n",
    "for i in range(0, k):\n",
    "    for j in range(sample_sort_data.size-1, 0, -1):\n",
    "        if sample_sort_data[j][1] < sample_sort_data[j-1][1]:\n",
    "            sample_sort_data[[j, j-1]] = sample_sort_data[[j-1, j]]\n",
    "\n",
    "smallest_k = sample_sort_data[:k]\n",
    "print(smallest_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 1.) (6, 2.) (5, 3.)]\n"
     ]
    }
   ],
   "source": [
    "# Making Finding Smallest K Into Function\n",
    "def smallest_k_partial_sort(array, k=1):\n",
    "    for i in range(0, k):\n",
    "        for j in range(array.size-1, 0, -1):\n",
    "            if array[j][1] < array[j-1][1]:\n",
    "                array[[j, j-1]] = array[[j-1, j]]\n",
    "\n",
    "    top_k = array[:k]\n",
    "    return top_k\n",
    "\n",
    "print(smallest_k_partial_sort(sample_sort_data, k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Partial Sort k=1: \n",
      "[[(2,  5.91607978)]\n",
      " [(2, 22.91287847)]]\n",
      "KNN - Partial Sort k=2: \n",
      "[[(2,  5.91607978) (1,  8.94427191)]\n",
      " [(2, 22.91287847) (1, 27.38612788)]]\n",
      "KNN - Partial Sort k=3: \n",
      "[[(2,  5.91607978) (1,  8.94427191) (0, 14.96662955)]\n",
      " [(2, 22.91287847) (1, 27.38612788) (0, 33.67491648)]]\n"
     ]
    }
   ],
   "source": [
    "# Make It All Into A Function\n",
    "def knn_bf_partial_sort(train_data, test_data ,k=1):\n",
    "    distance_matrix = np.zeros((test_data.shape[0], train_data.shape[0]), dtype=[(\"index\",int), (\"dist\",float)])\n",
    "\n",
    "    for row, test_vector in enumerate(test_data):\n",
    "        for col, train_vector in enumerate(train_data):\n",
    "            distance_matrix[row, col] = (col, euclidean(test_vector, train_vector))\n",
    "    \n",
    "    smallest_k_matrix = np.zeros((test_data.shape[0], k), dtype=[(\"index\",int), (\"dist\",float)])\n",
    "    for i, row in enumerate(distance_matrix):\n",
    "        smallest_k_matrix[i,:] = smallest_k_partial_sort(row, k)\n",
    "        \n",
    "    \n",
    "    return smallest_k_matrix\n",
    "\n",
    "\n",
    "print(\"KNN - Partial Sort k=1: \\n\" + str(knn_bf_partial_sort(train_data, test_data, 1)))\n",
    "print(\"KNN - Partial Sort k=2: \\n\" + str(knn_bf_partial_sort(train_data, test_data, 2)))\n",
    "print(\"KNN - Partial Sort k=3: \\n\" + str(knn_bf_partial_sort(train_data, test_data, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Brute Force - Max-Heap To Get Top K\n",
    "\n",
    "Here we use brute force KNN to find find all distances, then we will use a Max-Heap to find the smallest K. Finding smallest K will have a time complexity of O(nlogK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(1,  8.94427191) (2,  5.91607978)]\n",
      " [(1, 27.38612788) (2, 22.91287847)]]\n"
     ]
    }
   ],
   "source": [
    "# Quick Prototype #\n",
    "\n",
    "import heapq \n",
    "\n",
    "k = 2\n",
    "\n",
    "# Holds The Smallest K Data\n",
    "smallest_k = np.array(np.zeros((test_data.shape[0], k)), dtype=[(\"index\",int), (\"dist\",float)])\n",
    "\n",
    "for row, test_vector in enumerate(test_data):\n",
    "    \n",
    "    max_heap = []\n",
    "    \n",
    "    for col, train_vector in enumerate(train_data):\n",
    "        # Two Things To Note:\n",
    "        # 1. heapq Only Offers a Min-Heap, So We Negate The Priorty Value To Make It A Max-Heap\n",
    "        # 2. Tuples Are Compared By Their First Element, So We Switch The Typical Order Of Distance and Index\n",
    "        dist = (-1.*euclidean(test_vector, train_vector), col)\n",
    "        \n",
    "        # Max-Heap Should Only Be Size K, We Need To Fill It Since Its Initially Empty\n",
    "        if len(max_heap) < k:\n",
    "            heapq.heappush(max_heap, dist)\n",
    "        # If The Current Distance Is Less Than Max In Heap Then Remove Head And Add Current Distance\n",
    "        # Remember We Have To Use Reverse Logic Due To Negateing Priority Value\n",
    "        elif max_heap[0] < dist:\n",
    "            heapq.heapreplace(max_heap, dist)\n",
    "            \n",
    "    # We Swap Order Of Index and Distance and Un-Negate Distance\n",
    "    smallest_k[row,:] = [(x[1], -1.*x[0]) for x in max_heap]\n",
    "    \n",
    "    \n",
    "print(smallest_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Max Heap k=1: \n",
      "[[(2,  5.91607978)]\n",
      " [(2, 22.91287847)]]\n",
      "KNN - Max Heap k=2: \n",
      "[[(1,  8.94427191) (2,  5.91607978)]\n",
      " [(1, 27.38612788) (2, 22.91287847)]]\n",
      "KNN - Max Heap k=3: \n",
      "[[(0, 14.96662955) (1,  8.94427191) (2,  5.91607978)]\n",
      " [(0, 33.67491648) (1, 27.38612788) (2, 22.91287847)]]\n"
     ]
    }
   ],
   "source": [
    "def knn_bf_max_heap(train_data, test_data, k=1):\n",
    "    smallest_k = np.array(np.zeros((test_data.shape[0], k)), dtype=[(\"index\",int), (\"dist\",float)])\n",
    "\n",
    "    for row, test_vector in enumerate(test_data):\n",
    "\n",
    "        max_heap = []\n",
    "\n",
    "        for col, train_vector in enumerate(train_data):\n",
    "            # Two Things To Note:\n",
    "            # 1. heapq Only Offers a Min-Heap, So We Negate The Priorty Value To Make It A Max-Heap\n",
    "            # 2. Tuples Are Compared By Their First Element, So We Switch The Typical Order Of Distance and Index\n",
    "            dist = (-1.*euclidean(test_vector, train_vector), col)\n",
    "\n",
    "            # Max-Heap Should Only Be Size K, We Need To Fill It Since Its Initially Empty\n",
    "            if len(max_heap) < k:\n",
    "                heapq.heappush(max_heap, dist)\n",
    "            # If The Current Distance Is Less Than Max In Heap Then Remove Head And Add Current Distance\n",
    "            # Remember We Have To Use Reverse Logic Due To Negateing Priorty Value\n",
    "            elif max_heap[0] < dist:\n",
    "                heapq.heapreplace(max_heap, dist)\n",
    "\n",
    "        # We Swap Order Of Index and Distance and Un-Negate Distance\n",
    "        smallest_k[row,:] = [(x[1], -1.*x[0]) for x in max_heap]\n",
    "        \n",
    "    return smallest_k\n",
    "\n",
    "print(\"KNN - Max Heap k=1: \\n\" + str(knn_bf_max_heap(train_data, test_data, 1)))\n",
    "print(\"KNN - Max Heap k=2: \\n\" + str(knn_bf_max_heap(train_data, test_data, 2)))\n",
    "print(\"KNN - Max Heap k=3: \\n\" + str(knn_bf_max_heap(train_data, test_data, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Brute Force - Median of Medians To Find Top K\n",
    "Here we use brute force KNN to find find all distances, then we will use the Median of Medians algorithm to find the smallest K. Finding smallest K will have a time complexity of O(n)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median of Medians\n",
    "Median of Medians is an selection algorithm that finds the kth order statistic of an unordered list in O(n) time complexity. To find the smallest k, we will find the kth order statistic and then find all elements equal to or smaller than that order statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note Order Statistics Start At 0 And End at n-1\n",
      "Data: [17 16 15 14 13 12 11 10  9  8  7  6  5  4  3  2  1]\n",
      "0 Order Statistic: 1\n",
      "3rd Order Statistic: 4\n",
      "8th Order Statistic: 9\n",
      "14th Order Statistic: 15\n",
      "16th Order Statistic: 17\n"
     ]
    }
   ],
   "source": [
    "def medians_of_medians(array, k=0):\n",
    "    \n",
    "    # Base Case When Small Array Is Given - Just Find Median\n",
    "    if array.size <= 5:\n",
    "        return np.sort(array)[int(k)]\n",
    "    \n",
    "    # Make Lists Of Size 5 From Original Input    \n",
    "    subsets_size_five = np.array(list(map(lambda x: array[x:x+5], range(0, array.size, 5))))\n",
    "    \n",
    "    # Find The Median Of Every Sublist\n",
    "    # If Sublist Even Return One Of The Two Numbers\n",
    "    median_of_subsets = np.array(list(map(lambda x: np.sort(x)[int(x.size/2)], subsets_size_five)))\n",
    "    \n",
    "    # Find Median Of List Of Medians\n",
    "    mom = medians_of_medians(median_of_subsets, int(median_of_subsets.size/2))\n",
    "    \n",
    "    # Make Two Lists: Numbers Greater Than Median Of Medians and Less Than Median Of Medians\n",
    "    left = array[array < mom]\n",
    "    right = array[array > mom]\n",
    "    \n",
    "    # Position of Median Of Medians\n",
    "    pos_of_mom = left.size\n",
    "    \n",
    "    # Explore Numbers To Left or Right Unless We Found The Kth Order Statistic\n",
    "    if pos_of_mom < k:\n",
    "        return medians_of_medians(right, k-pos_of_mom-1 )\n",
    "    elif pos_of_mom > k:\n",
    "        return medians_of_medians(left, k)\n",
    "        \n",
    "    return mom\n",
    "    \n",
    "print(\"Note Order Statistics Start At 0 And End at n-1\")\n",
    "print(\"Data: \" + str(np.array(range(17, 0, -1))))\n",
    "print(\"0 Order Statistic: \" + str(medians_of_medians(np.array(range(17, 0, -1)), 0)))\n",
    "print(\"3rd Order Statistic: \" + str(medians_of_medians(np.array(range(17, 0, -1)), 3)))\n",
    "print(\"8th Order Statistic: \" + str(medians_of_medians(np.array(range(17, 0, -1)), 8)))\n",
    "print(\"14th Order Statistic: \" + str(medians_of_medians(np.array(range(17, 0, -1)), 14)))\n",
    "print(\"16th Order Statistic: \" + str(medians_of_medians(np.array(range(17, 0, -1)), 16)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      "[(0, 8.) (1, 7.) (2, 6.) (3, 5.) (4, 4.) (5, 3.) (6, 2.) (7, 1.)]\n",
      "(index, distance)\n",
      "0 Order Statistic: (7, 1.)\n",
      "3rd Order Statistic: (4, 4.)\n",
      "4th Order Statistic: (3, 5.)\n",
      "6th Order Statistic: (1, 7.)\n",
      "7th Order Statistic: (0, 8.)\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "# The Medians of Medians Algoirhtm Must Be Update To Work With The Paired Data We Are Using\n",
    "# Remember In The Distance Matrix We Store The Training Vector Index and The Distance\n",
    "\n",
    "        \n",
    "\n",
    "def medians_of_medians(array, k=0):\n",
    "    \n",
    "    # Base Case When Small Array Is Given - Just Find Median\n",
    "    if array.size <= 5:\n",
    "        return np.sort(array, order=\"dist\")[int(k)]\n",
    "    \n",
    "    # Make Lists Of Size 5 From Original Input    \n",
    "    subsets_size_five = np.array(list(map(lambda x: array[x:x+5], range(0, int(array.size), 5))))\n",
    "    \n",
    "    # Find The Median Of Every Sublist\n",
    "    # If Sublist Even Return One Of The Two Numbers\n",
    "    median_of_subsets = np.array(list(map(lambda x: np.sort(x, order=\"dist\")[int(x.size/2)], subsets_size_five)))\n",
    "    \n",
    "    # Find Median Of List Of Medians\n",
    "    mom = medians_of_medians(median_of_subsets, int(median_of_subsets.size/2))\n",
    "    \n",
    "    # Make Two Lists: Numbers Greater Than Median Of Medians and Less Than Median Of Medians    \n",
    "    left = array[array[\"dist\"] < mom[\"dist\"]]\n",
    "    right = array[array[\"dist\"] > mom[\"dist\"]]\n",
    "    \n",
    "    # Position of Median Of Medians\n",
    "    pos_of_mom = left.size\n",
    "\n",
    "    # Explore Numbers To Left or Right Unless We Found The Kth Order Statistic\n",
    "    if pos_of_mom < k:\n",
    "        return medians_of_medians(right, k-pos_of_mom-1 )\n",
    "    elif pos_of_mom > k:\n",
    "        return medians_of_medians(left, k)\n",
    "        \n",
    "    return mom\n",
    "\n",
    "sample_data = np.array([(0, 8), (1, 7), (2, 6), (3, 5), (4, 4), (5, 3), (6, 2), (7, 1)],\n",
    "                       dtype=[(\"index\",int), (\"dist\",float)])\n",
    "\n",
    "print(\"Data:\\n\"+ str(sample_data))\n",
    "print(\"(index, distance)\")\n",
    "print(\"0 Order Statistic: \" + str(medians_of_medians(sample_data, 0)))\n",
    "print(\"3rd Order Statistic: \" + str(medians_of_medians(sample_data, 3)))\n",
    "print(\"4th Order Statistic: \" + str(medians_of_medians(sample_data, 4)))\n",
    "print(\"6th Order Statistic: \" + str(medians_of_medians(sample_data, 6)))\n",
    "print(\"7th Order Statistic: \" + str(medians_of_medians(sample_data, 7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 2.) (7, 1.)]\n"
     ]
    }
   ],
   "source": [
    "# Making Finding Smallest K Into Function\n",
    "def smallest_k_median_of_medians(array, k=1):\n",
    "    kth_order_stat = medians_of_medians(array, k-1)\n",
    "    return array[array[\"dist\"] <= kth_order_stat[\"dist\"]]\n",
    "\n",
    "print(smallest_k_median_of_medians(sample_data, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Median of Medians k=1: \n",
      "[[(2,  5.91607978)]\n",
      " [(2, 22.91287847)]]\n",
      "KNN - Median of Medians k=2: \n",
      "[[(1,  8.94427191) (2,  5.91607978)]\n",
      " [(1, 27.38612788) (2, 22.91287847)]]\n",
      "KNN - Median of Medians k=3: \n",
      "[[(0, 14.96662955) (1,  8.94427191) (2,  5.91607978)]\n",
      " [(0, 33.67491648) (1, 27.38612788) (2, 22.91287847)]]\n"
     ]
    }
   ],
   "source": [
    "# Make It All Into A Function\n",
    "def knn_bf_median_of_medians(train_data, test_data ,k=1):\n",
    "    distance_matrix = np.zeros((test_data.shape[0], train_data.shape[0]), dtype=[(\"index\",int), (\"dist\",float)])\n",
    "\n",
    "    for row, test_vector in enumerate(test_data):\n",
    "        for col, train_vector in enumerate(train_data):\n",
    "            distance_matrix[row, col] = (col, euclidean(test_vector, train_vector))\n",
    "    \n",
    "    smallest_k_matrix = np.zeros((test_data.shape[0], k), dtype=[(\"index\",int), (\"dist\",float)])\n",
    "\n",
    "    for i, row in enumerate(distance_matrix):\n",
    "        smallest_k_matrix[i,:] = smallest_k_median_of_medians(row, k)\n",
    "        \n",
    "    return smallest_k_matrix\n",
    "\n",
    "print(\"KNN - Median of Medians k=1: \\n\" + str(knn_bf_median_of_medians(train_data, test_data, 1)))\n",
    "print(\"KNN - Median of Medians k=2: \\n\" + str(knn_bf_median_of_medians(train_data, test_data, 2)))\n",
    "print(\"KNN - Median of Medians k=3: \\n\" + str(knn_bf_median_of_medians(train_data, test_data, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro Select\n",
    "\n",
    "Uses Quick-Select to begin with, but switches to Median of Medians if recursion goes too deep. Gives faster average speed time while in worst case ensuring O(n) time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Introselect k=1: \n",
      "[[(2,  5.91607978)]\n",
      " [(2, 22.91287847)]]\n",
      "KNN - Introselect k=2: \n",
      "[[(2,  5.91607978) (1,  8.94427191)]\n",
      " [(2, 22.91287847) (1, 27.38612788)]]\n",
      "KNN - Introselect k=3: \n",
      "[[(2,  5.91607978) (1,  8.94427191) (0, 14.96662955)]\n",
      " [(2, 22.91287847) (1, 27.38612788) (0, 33.67491648)]]\n"
     ]
    }
   ],
   "source": [
    "def knn_bf_introselect(train_data, test_data ,k=1):\n",
    "    distance_matrix = np.zeros((test_data.shape[0], train_data.shape[0]), dtype=[(\"index\",int), (\"dist\",float)])\n",
    "\n",
    "    for row, test_vector in enumerate(test_data):\n",
    "        for col, train_vector in enumerate(train_data):\n",
    "            distance_matrix[row, col] = (col, euclidean(test_vector, train_vector))\n",
    "    \n",
    "    smallest_k_matrix = np.zeros((test_data.shape[0], k), dtype=[(\"index\",int), (\"dist\",float)])\n",
    "    \n",
    "    for i, row in enumerate(distance_matrix):\n",
    "        smallest_k_matrix[i,:] = np.partition(row, k-1, order=\"dist\")[:k]\n",
    "        \n",
    "    return smallest_k_matrix\n",
    "\n",
    "print(\"KNN - Introselect k=1: \\n\" + str(knn_bf_introselect(train_data, test_data, 1)))\n",
    "print(\"KNN - Introselect k=2: \\n\" + str(knn_bf_introselect(train_data, test_data, 2)))\n",
    "print(\"KNN - Introselect k=3: \\n\" + str(knn_bf_introselect(train_data, test_data, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Aside - Finding Median of A List of 5 Numbers Using 6 Comparisions\n",
    "When reading about median of medians here(https://www.ics.uci.edu/~eppstein/161/960130.html) the author mentions that it is possible to find the median of five elements with only six comparisons. This is more optimal compared to \n",
    "performing a full sort on all subsets. Out of pure interest I imeplement this here but do not use it in my code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_five_elements(array):\n",
    "    # Compare Index 0 and 1 And Possibly Swap\n",
    "    # One\n",
    "    if array[0][\"dist\"] > array[1][\"dist\"]:\n",
    "        array[[0, 1]] = array[[1, 0]]\n",
    "        \n",
    "    # Compare Index 2 and 3 And Possibly Swap\n",
    "    # Twon\n",
    "    if array[2][\"dist\"] > array[3][\"dist\"]:\n",
    "        array[[2, 3]] = array[[3, 2]]\n",
    "        \n",
    "    # Three\n",
    "    if array[2][\"dist\"] < array[0][\"dist\"]:\n",
    "        array[[1, 3]] = array[[3, 1]]\n",
    "        array[[0, 2]] = array[[2, 0]]\n",
    "        \n",
    "    array[[0, 4]] = array[[4, 0]]\n",
    "    \n",
    "    # Four\n",
    "    if array[0][\"dist\"] > array[1][\"dist\"]:\n",
    "        array[[0, 1]] = array[[1, 0]]\n",
    "    \n",
    "    # Five\n",
    "    if array[2][\"dist\"] > array[0][\"dist\"]:\n",
    "        array[[1, 3]] = array[[3, 1]]\n",
    "        array[[0, 2]] = array[[2, 0]]\n",
    "        \n",
    "    # Six\n",
    "    if array[0][\"dist\"] > array[3][\"dist\"]:\n",
    "        return array[3]\n",
    "    \n",
    "    return array[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Data\n",
    "rand_train = np.random.randn(5000,100)\n",
    "rand_test = np.random.randn(500,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.9 s, sys: 27.9 ms, total: 9.93 s\n",
      "Wall time: 9.93 s\n",
      "CPU times: user 10.6 s, sys: 47.4 ms, total: 10.6 s\n",
      "Wall time: 10.6 s\n",
      "CPU times: user 9.98 s, sys: 34.2 ms, total: 10 s\n",
      "Wall time: 10 s\n",
      "CPU times: user 9.83 s, sys: 38.4 ms, total: 9.87 s\n",
      "Wall time: 9.86 s\n"
     ]
    }
   ],
   "source": [
    "%time run_1 = knn_bf_full_sort(rand_train, rand_test, 1)\n",
    "%time run_2 = knn_bf_full_sort(rand_train, rand_test, 3)\n",
    "%time run_3 = knn_bf_full_sort(rand_train, rand_test, 5)\n",
    "%time run_4 = knn_bf_full_sort(rand_train, rand_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.4 s, sys: 32.3 ms, total: 20.5 s\n",
      "Wall time: 20.5 s\n",
      "CPU times: user 43.3 s, sys: 45.8 ms, total: 43.4 s\n",
      "Wall time: 43.4 s\n",
      "CPU times: user 1min 6s, sys: 54.2 ms, total: 1min 6s\n",
      "Wall time: 1min 6s\n",
      "CPU times: user 1min 33s, sys: 159 ms, total: 1min 33s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%time run_1 = knn_bf_partial_sort(rand_train, rand_test, 1)\n",
    "%time run_2 = knn_bf_partial_sort(rand_train, rand_test, 3)\n",
    "%time run_3 = knn_bf_partial_sort(rand_train, rand_test, 5)\n",
    "%time run_4 = knn_bf_partial_sort(rand_train, rand_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.68 s, sys: 16.8 ms, total: 8.7 s\n",
      "Wall time: 8.69 s\n",
      "CPU times: user 8.68 s, sys: 20.3 ms, total: 8.7 s\n",
      "Wall time: 8.69 s\n",
      "CPU times: user 8.73 s, sys: 19.5 ms, total: 8.75 s\n",
      "Wall time: 8.74 s\n",
      "CPU times: user 8.66 s, sys: 13.9 ms, total: 8.67 s\n",
      "Wall time: 8.67 s\n"
     ]
    }
   ],
   "source": [
    "%time run_1 = knn_bf_max_heap(rand_train, rand_test, 1)\n",
    "%time run_2 = knn_bf_max_heap(rand_train, rand_test, 3)\n",
    "%time run_3 = knn_bf_max_heap(rand_train, rand_test, 5)\n",
    "%time run_4 = knn_bf_max_heap(rand_train, rand_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.4 s, sys: 74.3 ms, total: 25.4 s\n",
      "Wall time: 25.4 s\n",
      "CPU times: user 24.8 s, sys: 67.3 ms, total: 24.8 s\n",
      "Wall time: 24.8 s\n",
      "CPU times: user 24.7 s, sys: 41.7 ms, total: 24.7 s\n",
      "Wall time: 24.7 s\n",
      "CPU times: user 24.5 s, sys: 36.8 ms, total: 24.6 s\n",
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "%time run_1 = knn_bf_median_of_medians(rand_train, rand_test, 1)\n",
    "%time run_2 = knn_bf_median_of_medians(rand_train, rand_test, 3)\n",
    "%time run_3 = knn_bf_median_of_medians(rand_train, rand_test, 5)\n",
    "%time run_4 = knn_bf_median_of_medians(rand_train, rand_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.86 s, sys: 19.4 ms, total: 9.88 s\n",
      "Wall time: 9.87 s\n",
      "CPU times: user 9.77 s, sys: 15.7 ms, total: 9.78 s\n",
      "Wall time: 9.78 s\n",
      "CPU times: user 9.81 s, sys: 27.3 ms, total: 9.83 s\n",
      "Wall time: 9.82 s\n",
      "CPU times: user 9.9 s, sys: 22.9 ms, total: 9.93 s\n",
      "Wall time: 9.92 s\n"
     ]
    }
   ],
   "source": [
    "%time run_1 = knn_bf_introselect(rand_train, rand_test, 1)\n",
    "%time run_2 = knn_bf_introselect(rand_train, rand_test, 3)\n",
    "%time run_3 = knn_bf_introselect(rand_train, rand_test, 5)\n",
    "%time run_4 = knn_bf_introselect(rand_train, rand_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knn_env_Python_3",
   "language": "python",
   "name": "knn_env_python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
